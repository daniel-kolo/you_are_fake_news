{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-03T00:42:25.970724Z",
     "start_time": "2019-11-03T00:42:23.753434Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"../data/reliable_news_prep\", \"r\") as reliable_file:\n",
    "    rel = [line.strip() for line in reliable_file]\n",
    "with open(\"../data/fake_news_prep\", \"r\") as fake_file:\n",
    "    fake = [line.strip() for line in fake_file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-03T00:42:25.980738Z",
     "start_time": "2019-11-03T00:42:25.975535Z"
    }
   },
   "outputs": [],
   "source": [
    "length=50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-03T00:42:26.102806Z",
     "start_time": "2019-11-03T00:42:25.983675Z"
    }
   },
   "outputs": [],
   "source": [
    "text = rel[:length]+fake[:length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-03T00:42:26.199898Z",
     "start_time": "2019-11-03T00:42:26.105755Z"
    }
   },
   "outputs": [],
   "source": [
    "labels = [0 if i<length else 1 for i in range(2*length)] # reliable - 0; fake - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-03T00:42:30.408664Z",
     "start_time": "2019-11-03T00:42:26.202223Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/miniconda3/envs/deep_learning/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/miniconda3/envs/deep_learning/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/miniconda3/envs/deep_learning/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/miniconda3/envs/deep_learning/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/miniconda3/envs/deep_learning/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/miniconda3/envs/deep_learning/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from training_preprocess import prepare_fastText_embedding_matrix as prepare_embedding\n",
    "from training_preprocess import sequence_vectorize\n",
    "from training_preprocess import train_val_test_split as split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-03T08:21:58.898136Z",
     "start_time": "2019-11-03T08:21:58.697501Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_val, X_test, Y_train, Y_test, Y_val = split(text, labels, 0.2, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-03T00:43:38.901557Z",
     "start_time": "2019-11-03T00:42:30.613139Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train, x_val, x_test, word_index = sequence_vectorize(X_train, X_val, X_test, sequence_length=1100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-03T00:51:06.756702Z",
     "start_time": "2019-11-03T00:43:38.906449Z"
    }
   },
   "outputs": [],
   "source": [
    "embedding_matrix = prepare_embedding(word_index, \"../data/cc.en.300.bin.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-03T00:51:06.806703Z",
     "start_time": "2019-11-03T00:51:06.759973Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import layers, models, optimizers, regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-03T00:51:06.873418Z",
     "start_time": "2019-11-03T00:51:06.808769Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def label_to_vector(labels):\n",
    "    array = np.zeros([len(labels), 2])\n",
    "    for i, label in enumerate(labels):\n",
    "        array[i, label] = 1\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-03T00:51:06.963672Z",
     "start_time": "2019-11-03T00:51:06.875809Z"
    }
   },
   "outputs": [],
   "source": [
    "def bidirectional_LSTM(embedding_dim, dropout_rate, input_shape, num_classes, is_embedding_trainable, embedding_matrix):\n",
    "    \n",
    "    # Add an Input Layer\n",
    "    input_layer = layers.Input((input_shape, ))\n",
    "\n",
    "    # Add the word embedding Layer\n",
    "    embedding_layer = layers.Embedding(input_dim=embedding_matrix.shape[0],\n",
    "                                       output_dim=embedding_dim,\n",
    "                                       weights=[embedding_matrix],\n",
    "                                       trainable=is_embedding_trainable)(input_layer)\n",
    "    embedding_layer = layers.SpatialDropout1D(0.6)(embedding_layer)\n",
    "    \n",
    "    # Add the LSTM Layer\n",
    "    lstm_layer = layers.Bidirectional(layers.LSTM(20))(embedding_layer)\n",
    "\n",
    "    # Add the output Layers\n",
    "    output_layer1 = layers.Dense(70, activation=\"relu\")(lstm_layer)\n",
    "    output_layer2 = layers.Dropout(dropout_rate)(output_layer1)\n",
    "    output_layer3 = layers.Dense(num_classes, activation=\"softmax\")(output_layer2)\n",
    "\n",
    "    # Compile the model\n",
    "    model = models.Model(inputs=input_layer, outputs=output_layer3)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-03T08:22:06.299755Z",
     "start_time": "2019-11-03T08:22:06.272780Z"
    }
   },
   "outputs": [],
   "source": [
    "y_train = label_to_vector(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-03T08:22:07.176273Z",
     "start_time": "2019-11-03T08:22:07.165004Z"
    }
   },
   "outputs": [],
   "source": [
    "y_val = label_to_vector(Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-03T06:08:55.491607Z",
     "start_time": "2019-11-03T00:51:07.164399Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/miniconda3/envs/deep_learning/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/miniconda3/envs/deep_learning/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/miniconda3/envs/deep_learning/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 70000 samples, validate on 20000 samples\n",
      "Epoch 1/10\n",
      " - 3173s - loss: 0.1929 - acc: 0.9244 - val_loss: 0.1021 - val_acc: 0.9665\n",
      "Epoch 2/10\n",
      " - 3176s - loss: 0.0812 - acc: 0.9722 - val_loss: 0.0774 - val_acc: 0.9729\n",
      "Epoch 3/10\n",
      " - 3180s - loss: 0.0634 - acc: 0.9788 - val_loss: 0.0768 - val_acc: 0.9751\n",
      "Epoch 4/10\n",
      " - 3175s - loss: 0.0452 - acc: 0.9859 - val_loss: 0.0840 - val_acc: 0.9746\n",
      "Epoch 5/10\n",
      " - 3178s - loss: 0.0338 - acc: 0.9891 - val_loss: 0.0906 - val_acc: 0.9758\n",
      "Epoch 6/10\n",
      " - 3178s - loss: 0.0702 - acc: 0.9735 - val_loss: 0.0877 - val_acc: 0.9755\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "model = bidirectional_LSTM(300, 0.2, 1100, 2, True, embedding_matrix)\n",
    "model.compile(optimizer='Adam', loss=\"binary_crossentropy\", metrics=['accuracy'])\n",
    "\n",
    "callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)]\n",
    "\n",
    "model.fit(x_train,\n",
    "          y_train,\n",
    "          epochs=10,\n",
    "          callbacks=callbacks,\n",
    "          validation_data=(x_val, y_val),\n",
    "          verbose=2,  # Logs once per epoch.\n",
    "          batch_size=128)\n",
    "\n",
    "model.save_weights('../data/sequence_model_with_pre_trained_embedding.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-03T08:22:09.119379Z",
     "start_time": "2019-11-03T08:22:09.112249Z"
    }
   },
   "outputs": [],
   "source": [
    "y_test = label_to_vector(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-03T08:18:41.920374Z",
     "start_time": "2019-11-03T08:11:09.832353Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 452s 45ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0924303956180811, 0.9742]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:deep_learning]",
   "language": "python",
   "name": "conda-env-deep_learning-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
